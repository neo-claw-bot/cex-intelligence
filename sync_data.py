#!/usr/bin/env python3
"""
æ•°æ®åŒæ­¥è„šæœ¬
å°†é‡‡é›†çš„æ•°æ®åŒæ­¥åˆ°ç½‘ç«™ç›®å½•
æ”¯æŒåŒæ—¶é—´å­—æ®µ: discovered_at (å‘ç°æ—¶é—´) å’Œ event_date (äº‹ä»¶æ—¶é—´)
"""

import json
import shutil
from datetime import datetime
from pathlib import Path

def sync_data():
    """åŒæ­¥æ•°æ®åˆ°ç½‘ç«™ç›®å½•"""
    
    # æºæ•°æ®ç›®å½• (æ ¹ç›®å½•)
    source_dir = Path(__file__).parent / "data"
    
    # ç›®æ ‡ç›®å½• (webåº”ç”¨)
    web_data_dir = Path(__file__).parent / "web" / "data" / "intelligence"
    web_data_dir.mkdir(parents=True, exist_ok=True)
    
    # æ‰¾åˆ°æœ€æ–°çš„æ•°æ®æ–‡ä»¶
    files = sorted(source_dir.glob("daily_*.json"))
    if not files:
        print("âŒ æ— æ•°æ®æ–‡ä»¶")
        return False
    
    latest = files[-1]
    print(f"ğŸ“‚ è¯»å–æºæ•°æ®: {latest}")
    
    # è¯»å–å¹¶è½¬æ¢æ ¼å¼
    with open(latest, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ç”Ÿæˆæ—¥æœŸæ ¼å¼çš„æ–‡ä»¶å (YYYY-MM-DD.json)
    today = datetime.now().strftime("%Y-%m-%d")
    target_file = web_data_dir / f"{today}.json"
    
    # å½“å‰å‘ç°æ—¶é—´ï¼ˆç³»ç»Ÿé‡‡é›†æ—¶é—´ï¼‰
    discovered_at = data.get("timestamp", datetime.now().isoformat())
    
    # å¤„ç†å…³é”®è­¦æŠ¥ï¼Œæ·»åŠ åŒæ—¶é—´å­—æ®µ
    key_alerts = []
    for alert in data.get("key_alerts", []):
        # äº‹ä»¶å‘ç”Ÿæ—¶é—´ï¼ˆä»alertä¸­è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å‘ç°æ—¶é—´ï¼‰
        event_date = alert.get("date", discovered_at[:10])
        
        processed_alert = {
            "exchange": alert.get("exchange"),
            "severity": alert.get("severity", "medium"),
            "title": alert.get("title"),
            "description": alert.get("description"),
            "source": alert.get("source", "Unknown"),
            "url": alert.get("url", ""),
            "urls": alert.get("urls", []),
            "event_date": event_date,  # äº‹ä»¶å‘ç”Ÿæ—¶é—´
            "discovered_at": discovered_at,  # æˆ‘ä»¬å‘ç°çš„æ—¶é—´
            "tags": alert.get("tags", ["security"])
        }
        key_alerts.append(processed_alert)
    
    # è½¬æ¢æ•°æ®æ ¼å¼ä»¥é€‚åº”ç½‘ç«™
    web_data = {
        "date": today,
        "timestamp": discovered_at,
        "collected_at": discovered_at,
        "discovered_at": discovered_at,  # å‘ç°æ—¶é—´ï¼ˆç³»ç»Ÿæ—¶é—´ï¼‰
        "summary": {
            "total_exchanges": len(data.get("exchanges", [])),
            "alerted_exchanges": len([e for e in data.get("exchanges", []) if e.get("alert_level") != "none"]),
            "critical_alerts": len([a for a in key_alerts if a.get("severity") == "critical"]),
            "high_alerts": len([a for a in key_alerts if a.get("severity") == "high"])
        },
        "exchanges": data.get("exchanges", []),
        "key_alerts": key_alerts,
        "alerts": key_alerts
    }
    
    # ä¿å­˜åˆ°ç½‘ç«™ç›®å½•
    with open(target_file, 'w', encoding='utf-8') as f:
        json.dump(web_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ•°æ®å·²åŒæ­¥: {latest} â†’ {target_file}")
    print(f"ğŸ“Š ç‹¬ç«‹è­¦æŠ¥æ•°é‡: {len(key_alerts)}")
    for a in key_alerts:
        print(f"  - [äº‹ä»¶:{a['event_date']}] [å‘ç°:{a['discovered_at'][:10]}] {a['title']}")
    
    # åŒæ—¶å¤åˆ¶åˆ° site/ ç›®å½•
    site_data_dir = Path(__file__).parent / "site"
    site_data_dir.mkdir(exist_ok=True)
    
    with open(site_data_dir / "latest.json", 'w', encoding='utf-8') as f:
        json.dump(web_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… é™æ€æ•°æ®å·²æ›´æ–°: site/latest.json")
    
    return True

if __name__ == "__main__":
    sync_data()
