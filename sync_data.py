#!/usr/bin/env python3
"""
æ•°æ®åŒæ­¥è„šæœ¬
å°†é‡‡é›†çš„æ•°æ®åŒæ­¥åˆ°ç½‘ç«™ç›®å½•
"""

import json
import shutil
from datetime import datetime
from pathlib import Path

def sync_data():
    """åŒæ­¥æ•°æ®åˆ°ç½‘ç«™ç›®å½•"""
    
    # æºæ•°æ®ç›®å½• (æ ¹ç›®å½•)
    source_dir = Path(__file__).parent / "data"
    
    # ç›®æ ‡ç›®å½• (webåº”ç”¨)
    web_data_dir = Path(__file__).parent / "web" / "data" / "intelligence"
    web_data_dir.mkdir(parents=True, exist_ok=True)
    
    # æ‰¾åˆ°æœ€æ–°çš„æ•°æ®æ–‡ä»¶
    files = sorted(source_dir.glob("daily_*.json"))
    if not files:
        print("âŒ æ— æ•°æ®æ–‡ä»¶")
        return False
    
    latest = files[-1]
    print(f"ğŸ“‚ è¯»å–æºæ•°æ®: {latest}")
    
    # è¯»å–å¹¶è½¬æ¢æ ¼å¼
    with open(latest, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ç”Ÿæˆæ—¥æœŸæ ¼å¼çš„æ–‡ä»¶å (YYYY-MM-DD.json)
    today = datetime.now().strftime("%Y-%m-%d")
    target_file = web_data_dir / f"{today}.json"
    
    # è½¬æ¢æ•°æ®æ ¼å¼ä»¥é€‚åº”ç½‘ç«™æ¨¡æ¿
    exchanges_list = []
    for e in data.get("exchanges", []):
        # æ„å»ºè­¦æŠ¥åˆ—è¡¨
        alerts = []
        if e.get("fintelegram_reports"):
            for report in e.get("fintelegram_reports"):
                alerts.append({
                    "type": "fintelegram",
                    "title": report,
                    "severity": "high",
                    "description": report,
                    "source": "FinTelegram"
                })
        
        exchange_data = {
            "name": e.get("exchange"),
            "status": "warning" if e.get("alert_level") in ["high", "critical"] else "normal",
            "severity": e.get("alert_level", "none"),
            "alerts_count": len(alerts),
            "alerts": alerts,
            "twitter_sentiment": "neutral",
            "news_count": len(e.get("web_articles", [])),
            "sources": ["FinTelegram"] if alerts else []
        }
        exchanges_list.append(exchange_data)
    
    # æ„å»ºå…³é”®è­¦æŠ¥åˆ—è¡¨ï¼ˆç”¨äºç½‘ç«™æ¨¡æ¿æ˜¾ç¤ºï¼‰
    alerts_list = []
    for e in data.get("exchanges", []):
        if e.get("alert_level") in ["high", "critical"]:
            # å¤„ç† FinTelegram æŠ¥å‘Šï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸ï¼‰
            reports = e.get("fintelegram_reports", [])
            urls = []
            descriptions = []
            
            for r in reports:
                if isinstance(r, dict):
                    descriptions.append(f"{r.get('date', '')}: {r.get('title', '')}")
                    if r.get('url'):
                        urls.append(r.get('url'))
                else:
                    descriptions.append(r)
            
            # é»˜è®¤URLåˆ—è¡¨ï¼ˆå¦‚æœreportsä¸­æ²¡æœ‰URLï¼‰
            if not urls:
                urls = ["https://fintelegram.com"]
            
            # æ„å»ºè­¦æŠ¥è¯¦æƒ…
            alert_info = {
                "exchange": e.get("exchange"),
                "severity": e.get("alert_level"),
                "title": f"{e.get('exchange')} - {e.get('alert_level').upper()} é£é™©è­¦æŠ¥",
                "description": "; ".join(descriptions) if descriptions else "å‘ç°é£é™©ä¿¡å·",
                "source": "FinTelegram" if reports else "Monitor",
                "url": urls[0] if urls else "https://fintelegram.com",  # ä¸»URL
                "urls": urls,  # æ‰€æœ‰URLåˆ—è¡¨
                "tags": ["security"] if reports else []
            }
            alerts_list.append(alert_info)
    
    # è½¬æ¢æ•°æ®æ ¼å¼ä»¥é€‚åº”ç½‘ç«™
    web_data = {
        "date": today,
        "timestamp": data.get("timestamp", ""),
        "collected_at": data.get("timestamp", ""),  # æ¨¡æ¿ä½¿ç”¨è¿™ä¸ªå­—æ®µ
        "summary": {
            "total_exchanges": len(data.get("exchanges", [])),
            "alerted_exchanges": len([e for e in data.get("exchanges", []) if e.get("alert_level") != "none"]),
            "critical_alerts": len([e for e in data.get("exchanges", []) if e.get("alert_level") == "critical"]),
            "high_alerts": len([e for e in data.get("exchanges", []) if e.get("alert_level") == "high"])
        },
        "exchanges": data.get("exchanges", []),
        "exchanges_list": exchanges_list,  # æ¨¡æ¿ä½¿ç”¨è¿™ä¸ªæ ¼å¼
        "key_alerts": alerts_list,  # å…³é”®è­¦æŠ¥
        "alerts": alerts_list  # ç½‘ç«™æ¨¡æ¿ä½¿ç”¨è¿™ä¸ªå­—æ®µæ˜¾ç¤ºè­¦æŠ¥
    }
    
    # ä¿å­˜åˆ°ç½‘ç«™ç›®å½•
    with open(target_file, 'w', encoding='utf-8') as f:
        json.dump(web_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ•°æ®å·²åŒæ­¥: {latest} â†’ {target_file}")
    
    # åŒæ—¶å¤åˆ¶åˆ° site/ ç›®å½•ç”¨äºé™æ€è®¿é—®
    site_data_dir = Path(__file__).parent / "site"
    site_data_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆç½‘ç«™ä¸“ç”¨æ•°æ®æ–‡ä»¶
    with open(site_data_dir / "latest.json", 'w', encoding='utf-8') as f:
        json.dump(web_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… é™æ€æ•°æ®å·²æ›´æ–°: site/latest.json")
    
    return True

if __name__ == "__main__":
    sync_data()
