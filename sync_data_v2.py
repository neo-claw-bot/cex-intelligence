#!/usr/bin/env python3
"""
æ•°æ®åŒæ­¥è„šæœ¬ v2
å¤„ç†å¸¦åˆ†ç±»çš„æ–°æ•°æ®ç»“æ„
"""

import json
import shutil
from datetime import datetime
from pathlib import Path


def sync_data():
    """åŒæ­¥æ•°æ®åˆ°ç½‘ç«™ç›®å½•"""
    
    # æºæ•°æ®ç›®å½• (æ ¹ç›®å½•)
    source_dir = Path(__file__).parent / "data"
    
    # ç›®æ ‡ç›®å½• (webåº”ç”¨)
    web_data_dir = Path(__file__).parent / "web" / "data" / "intelligence"
    web_data_dir.mkdir(parents=True, exist_ok=True)
    
    # æ‰¾åˆ°æœ€æ–°çš„æ•°æ®æ–‡ä»¶ï¼ˆåªè¯» daily_*.jsonï¼‰
    files = sorted(source_dir.glob("daily_*.json"))
    if not files:
        print("âŒ æ— æ•°æ®æ–‡ä»¶")
        return False
    
    latest = files[-1]
    print(f"ğŸ“‚ è¯»å–æºæ•°æ®: {latest}")
    
    # è¯»å–æ•°æ®
    with open(latest, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ç”Ÿæˆæ—¥æœŸæ ¼å¼çš„æ–‡ä»¶å
    today = datetime.now().strftime("%Y-%m-%d")
    target_file = web_data_dir / f"{today}.json"
    
    # å¤„ç†è­¦æŠ¥æ•°æ®ï¼Œç¡®ä¿æ¯ä¸ªéƒ½æœ‰ category
    all_alerts = data.get('all_alerts', data.get('alerts', []))
    
    # ä¸ºæ²¡æœ‰ category çš„è­¦æŠ¥æ·»åŠ é»˜è®¤å€¼
    for alert in all_alerts:
        if 'category' not in alert:
            # åŸºäºå…³é”®è¯ç®€å•åˆ†ç±»
            title_desc = (alert.get('title', '') + ' ' + alert.get('description', '')).lower()
            if any(k in title_desc for k in ['hack', 'stolen', 'breach', 'ddos', 'æ¼æ´', 'æ”»å‡»']):
                alert['category'] = 'security_attack'
            elif any(k in title_desc for k in ['ç ´äº§', 'è¢«æ•', 'æŒ¤å…‘', 'å®•æœº']):
                alert['category'] = 'operational_risk'
            else:
                alert['category'] = 'dispute_compliance'
        
        # ç¡®ä¿æœ‰ discovered_at
        if 'discovered_at' not in alert:
            alert['discovered_at'] = data.get('timestamp', datetime.now().isoformat())
    
    # æŒ‰åˆ†ç±»ç»Ÿè®¡
    categories = {
        'security_attack': [],
        'dispute_compliance': [],
        'operational_risk': []
    }
    
    for alert in all_alerts:
        cat = alert.get('category', 'dispute_compliance')
        if cat in categories:
            categories[cat].append(alert)
    
    # æ„å»º web æ•°æ®æ ¼å¼
    web_data = {
        'date': today,
        'timestamp': data.get('timestamp', datetime.now().isoformat()),
        'collected_at': data.get('timestamp', datetime.now().isoformat()),
        'discovered_at': datetime.now().isoformat(),
        'summary': {
            'total_exchanges': 30,
            'total_alerts': len(all_alerts),
            'alerted_exchanges': len(set(a.get('exchange') for a in all_alerts)),
            'critical_alerts': len([a for a in all_alerts if a.get('severity') == 'critical']),
            'high_alerts': len([a for a in all_alerts if a.get('severity') == 'high'])
        },
        'categories': {
            'security_attack': {
                'count': len(categories['security_attack']),
                'alerts': categories['security_attack']
            },
            'dispute_compliance': {
                'count': len(categories['dispute_compliance']),
                'alerts': categories['dispute_compliance']
            },
            'operational_risk': {
                'count': len(categories['operational_risk']),
                'alerts': categories['operational_risk']
            }
        },
        'alerts': all_alerts,
        'key_alerts': all_alerts,  # å…¼å®¹æ—§æ¨¡æ¿
        'exchanges': data.get('exchanges', [])
    }
    
    # ä¿å­˜åˆ°ç½‘ç«™ç›®å½•
    with open(target_file, 'w', encoding='utf-8') as f:
        json.dump(web_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ•°æ®å·²åŒæ­¥: {latest} â†’ {target_file}")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"   æ€»è­¦æŠ¥: {len(all_alerts)}")
    print(f"   ğŸ”´ æ”»å‡»äº‹ä»¶: {len(categories['security_attack'])}")
    print(f"   ğŸŸ  åˆè§„äº‰è®®: {len(categories['dispute_compliance'])}")
    print(f"   ğŸŸ¡ è¿è¥é£é™©: {len(categories['operational_risk'])}")
    
    # åŒæ—¶å¤åˆ¶åˆ° site/ ç›®å½•
    site_data_dir = Path(__file__).parent / "site"
    site_data_dir.mkdir(exist_ok=True)
    
    with open(site_data_dir / "latest.json", 'w', encoding='utf-8') as f:
        json.dump(web_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… é™æ€æ•°æ®å·²æ›´æ–°: site/latest.json")
    
    # ç”Ÿæˆç®€æŠ¥æ–‡æœ¬
    generate_briefing(web_data, site_data_dir)
    
    return True


def generate_briefing(data: dict, output_dir: Path):
    """ç”Ÿæˆç®€æŠ¥æ–‡æœ¬"""
    
    summary = data.get('summary', {})
    categories = data.get('categories', {})
    
    briefing = f"""ğŸ¯ CEX æ¯æ—¥ç®€æŠ¥ - {data.get('date', datetime.now().strftime('%Y-%m-%d'))}

ğŸ“Š ä»Šæ—¥æ¦‚å†µ
â€¢ ç›‘æ§äº¤æ˜“æ‰€: {summary.get('total_exchanges', 30)} ä¸ª
â€¢ é£é™©äº¤æ˜“æ‰€: {summary.get('alerted_exchanges', 0)} ä¸ª
â€¢ æ€»æƒ…æŠ¥æ•°: {summary.get('total_alerts', 0)} æ¡

ğŸ“ˆ åˆ†ç±»ç»Ÿè®¡
â€¢ ğŸ”´ ç½‘ç»œæ”»å‡»äº‹ä»¶: {categories.get('security_attack', {}).get('count', 0)} æ¡
â€¢ ğŸŸ  åˆè§„äº‰è®®é—®é¢˜: {categories.get('dispute_compliance', {}).get('count', 0)} æ¡
â€¢ ğŸŸ¡ è¿è¥é£é™©äº‹ä»¶: {categories.get('operational_risk', {}).get('count', 0)} æ¡

"""
    
    # æ·»åŠ å…³é”®è­¦æŠ¥
    alerts = data.get('alerts', [])
    critical_high = [a for a in alerts if a.get('severity') in ['critical', 'high']]
    
    if critical_high:
        briefing += "ğŸš¨ é‡ç‚¹å…³æ³¨\n"
        for alert in critical_high[:5]:
            cat_emoji = {
                'security_attack': 'ğŸ”´',
                'dispute_compliance': 'ğŸŸ ',
                'operational_risk': 'ğŸŸ¡'
            }.get(alert.get('category'), 'âšª')
            briefing += f"{cat_emoji} [{alert.get('exchange')}] {alert.get('title', '')}\n"
    else:
        briefing += "âœ… ä»Šæ—¥æ— é‡å¤§é£é™©äº‹ä»¶\n"
    
    briefing += f"""
â° ç”Ÿæˆæ—¶é—´: {data.get('timestamp', datetime.now().isoformat())}
ğŸ”— è¯¦ç»†æŠ¥å‘Š: https://cex-intelligence-production.up.railway.app
"""
    
    with open(output_dir / "briefing.txt", 'w', encoding='utf-8') as f:
        f.write(briefing)
    
    print(f"âœ… ç®€æŠ¥å·²ç”Ÿæˆ: site/briefing.txt")


if __name__ == "__main__":
    sync_data()
