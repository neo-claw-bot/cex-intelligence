#!/usr/bin/env python3
"""
CEX æ¯æ—¥ç®€æŠ¥ç”Ÿæˆå™¨ - ä¸­æ–‡ç‰ˆï¼ˆæ”¹è¿›ç‰ˆï¼‰
ç”¨äºå®šæ—¶ä»»åŠ¡ç”Ÿæˆæ¯æ—¥ç®€æŠ¥ï¼ˆä¸­æ–‡+å‡†ç¡®URLå¼•ç”¨ï¼‰
"""

import os
import json
import subprocess
from datetime import datetime, timedelta
from pathlib import Path

def call_grok(prompt: str, tools: list) -> dict:
    """è°ƒç”¨ Grok API"""
    api_key = os.getenv("XAI_API_KEY")
    data = {
        "model": "grok-4-1-fast-reasoning",
        "input": [{"role": "user", "content": prompt}],
        "tools": tools
    }
    
    curl_cmd = [
        "curl", "-s", "--max-time", "90",
        "https://api.x.ai/v1/responses",
        "-H", "Content-Type: application/json",
        "-H", f"Authorization: Bearer {api_key}",
        "-d", json.dumps(data, ensure_ascii=False)
    ]
    
    result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=95)
    return json.loads(result.stdout) if result.returncode == 0 else {"error": result.stderr}

def extract_text(response: dict) -> str:
    """æå–å“åº”æ–‡æœ¬"""
    try:
        for item in response.get("output", []):
            if item.get("type") == "message" or item.get("role") == "assistant":
                for content in item.get("content", []):
                    if content.get("type") in ["text", "output_text"]:
                        return content.get("text", "")
    except:
        pass
    return ""

def is_generic_url(url: str) -> bool:
    """æ£€æŸ¥ URL æ˜¯å¦ä¸ºé€šç”¨é“¾æ¥ï¼ˆå®˜ç½‘é¦–é¡µç­‰ï¼‰"""
    if not url:
        return True
    
    generic_patterns = [
        "twitter.com/home",
        "twitter.com",
        "x.com",
        "kucoin.com",
        "binance.com",
        "coinbase.com",
        "bitget.com",
        "kraken.com",
        "okx.com",
        "bybit.com",
        "fma.gv.at",
        "fintelegram.com",
        "coindesk.com",
        "cointelegraph.com"
    ]
    
    url_lower = url.lower().rstrip('/')
    for pattern in generic_patterns:
        if url_lower == f"https://{pattern}" or url_lower == f"http://{pattern}" or url_lower == f"https://www.{pattern}" or url_lower == f"http://www.{pattern}":
            return True
    
    return False

def collect_daily_intel() -> dict:
    """é‡‡é›†æ¯æ—¥æƒ…æŠ¥ï¼ˆä¸­æ–‡ç‰ˆï¼‰"""
    exchanges = [
        # CER.live æŒ‰äº¤æ˜“é‡å‰20
        "Binance", "MEXC", "Gate", "Bitget", "OKX", "HTX", "Bybit", "Coinbase",
        "CoinW", "BitMart", "Crypto.com", "DigiFinex", "LBank", "Upbit", "Toobit",
        "WEEX", "P2B", "XT.COM", "Tapbit", "Kraken",
        # CER.live å®‰å…¨è¯„åˆ†å‰åˆ—
        "KuCoin", "WhiteBIT", "Deribit"
    ]
    today = datetime.now().strftime("%Y-%m-%d")
    
    prompt = f"""æœç´¢å¹¶ç”ŸæˆCEXäº¤æ˜“æ‰€æƒ…æŠ¥ç®€æŠ¥ï¼ˆç”¨ä¸­æ–‡å›å¤ï¼‰ã€‚

ç›‘æ§äº¤æ˜“æ‰€: {', '.join(exchanges)}

æœç´¢å†…å®¹ï¼ˆæœ€è¿‘24-48å°æ—¶ï¼‰:
1. å®‰å…¨äº‹ä»¶æˆ–é»‘å®¢æ”»å‡»
2. æç°/å­˜æ¬¾é—®é¢˜  
3. ç›‘ç®¡è¡ŒåŠ¨æˆ–æ³•å¾‹é—®é¢˜
4. æœåŠ¡ä¸­æ–­æˆ–æŠ€æœ¯æ•…éšœ
5. è¯ˆéª—è­¦å‘Šæˆ–ç”¨æˆ·æŠ•è¯‰
6. é‡å¤§å…¬å‘Š

é‡è¦ï¼šå¯¹äºæ¯æ¡æƒ…æŠ¥ï¼Œè¯·æä¾›ï¼š
- å…·ä½“çš„æ–°é—»æ–‡ç« URLï¼ˆå¦‚ https://coindesk.com/.../article-nameï¼‰
- æˆ–å…·ä½“çš„æ¨æ–‡é“¾æ¥ï¼ˆå¦‚ https://twitter.com/username/status/1234567890ï¼‰
- ä¸è¦ä½¿ç”¨äº¤æ˜“æ‰€å®˜ç½‘ä¸»é¡µä½œä¸ºURL
- å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“çš„æ–°é—»é“¾æ¥ï¼Œurlå­—æ®µç•™ç©º
- tagså­—æ®µï¼šæ·»åŠ æ¥æºæ ‡ç­¾æ•°ç»„ï¼Œå¯é€‰å€¼ï¼š
  * "twitter" - X/Twitteræ¥æº
  * "news" - æ–°é—»åª’ä½“ï¼ˆCoinDesk, The Blockç­‰ï¼‰
  * "official" - äº¤æ˜“æ‰€å®˜æ–¹å…¬å‘Š
  * "user_report" - ç”¨æˆ·æŠ•è¯‰/æŠ¥å‘Š
  * "regulatory" - ç›‘ç®¡æœºæ„
  * "security" - å®‰å…¨å…¬å¸/å®¡è®¡
  * "forum" - è®ºå›/Reddit

è¿”å›æ ¼å¼ï¼ˆä¸­æ–‡JSONï¼‰ï¼š
{{
  "summary": "ç”¨ä¸­æ–‡å†™çš„æ•´ä½“æ‘˜è¦",
  "alerts": [
    {{
      "exchange": "äº¤æ˜“æ‰€åç§°",
      "severity": "critical|high|medium|low", 
      "title": "ä¸­æ–‡æ ‡é¢˜",
      "description": "ä¸­æ–‡è¯¦ç»†æè¿°",
      "url": "å…·ä½“çš„æ–°é—»æˆ–æ¨æ–‡é“¾æ¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç•™ç©º",
      "source_name": "æ¥æºåç§°ï¼ˆå¦‚CoinDeskã€The Blockã€Xç”¨æˆ·@usernameï¼‰",
      "tags": ["twitter", "news", "official", "user_report"] // æ ‡ç­¾æ•°ç»„
    }}
  ],
  "exchange_status": {{
    "Binance": {{"status": "normal|warning|critical", "notes": "ä¸­æ–‡è¯´æ˜", "url": "å…·ä½“é“¾æ¥æˆ–ç©º"}},
    "OKX": {{"status": "normal|warning|critical", "notes": "ä¸­æ–‡è¯´æ˜", "url": "å…·ä½“é“¾æ¥æˆ–ç©º"}},
    "Coinbase": {{"status": "normal|warning|critical", "notes": "ä¸­æ–‡è¯´æ˜", "url": "å…·ä½“é“¾æ¥æˆ–ç©º"}},
    "Bybit": {{"status": "normal|warning|critical", "notes": "ä¸­æ–‡è¯´æ˜", "url": "å…·ä½“é“¾æ¥æˆ–ç©º"}},
    "Bitget": {{"status": "normal|warning|critical", "notes": "ä¸­æ–‡è¯´æ˜", "url": "å…·ä½“é“¾æ¥æˆ–ç©º"}},
    "Kraken": {{"status": "normal|warning|critical", "notes": "ä¸­æ–‡è¯´æ˜", "url": "å…·ä½“é“¾æ¥æˆ–ç©º"}},
    "KuCoin": {{"status": "normal|warning|critical", "notes": "ä¸­æ–‡è¯´æ˜", "url": "å…·ä½“é“¾æ¥æˆ–ç©º"}}
  }},
  "fintelegram_highlights": [
    {{"content": "ä¸­æ–‡å†…å®¹", "url": "å…·ä½“æ–‡ç« é“¾æ¥æˆ–ç©º", "source_name": "æ¥æº"}}
  ],
  "sources": [
    {{"name": "æ¥æºåç§°", "url": "å…·ä½“é“¾æ¥", "type": "news|twitter|official"}}
  ]
}}

æ³¨æ„ï¼š
1. æ‰€æœ‰æ–‡æœ¬å¿…é¡»ç”¨ä¸­æ–‡
2. URL å¿…é¡»æ˜¯å…·ä½“çš„æ–°é—»æ–‡ç« æˆ–æ¨æ–‡é“¾æ¥ï¼Œä¸è¦ç”¨å®˜ç½‘ä¸»é¡µ
3. å¦‚æœæ‰¾ä¸åˆ°å…·ä½“æ¥æºï¼Œurl å­—æ®µç•™ç©ºå­—ç¬¦ä¸²""
4. ä¼˜å…ˆä½¿ç”¨çŸ¥åæ–°é—»æºï¼šCoinDesk, The Block, Cointelegraph, Decryptç­‰"""

    print(f"ğŸ” æ­£åœ¨é‡‡é›† {today} çš„æƒ…æŠ¥...")
    response = call_grok(prompt, [{"type": "x_search"}, {"type": "web_search"}])
    text = extract_text(response)
    
    try:
        data = json.loads(text) if text else {}
        
        # è¿‡æ»¤æ‰é€šç”¨ URL
        if data.get("alerts"):
            for alert in data["alerts"]:
                if is_generic_url(alert.get("url", "")):
                    alert["url"] = ""
        
        if data.get("exchange_status"):
            for ex, info in data["exchange_status"].items():
                if is_generic_url(info.get("url", "")):
                    info["url"] = ""
        
        data["date"] = today
        data["collected_at"] = datetime.now().isoformat()
        return data
    except Exception as e:
        print(f"è§£æé”™è¯¯: {e}")
        return {
            "date": today,
            "collected_at": datetime.now().isoformat(),
            "error": str(e),
            "summary": "æ•°æ®é‡‡é›†å¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•",
            "alerts": [],
            "exchange_status": {ex: {"status": "normal", "notes": "", "url": ""} for ex in exchanges},
            "fintelegram_highlights": [],
            "sources": []
        }

def save_intel(data: dict):
    """ä¿å­˜æƒ…æŠ¥"""
    # ä¿å­˜åˆ°é¡¹ç›®ç›®å½•
    data_dir = Path("/Users/neo/.openclaw/workspace-cex-intelligence/data/intelligence")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜åˆ° web ç›®å½•ï¼ˆç”¨äºéƒ¨ç½²ï¼‰
    web_data_dir = Path("/Users/neo/.openclaw/workspace-cex-intelligence/web/data/intelligence")
    web_data_dir.mkdir(parents=True, exist_ok=True)
    
    filepath = data_dir / f"{data['date']}.json"
    web_filepath = web_data_dir / f"{data['date']}.json"
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    with open(web_filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ å·²ä¿å­˜: {filepath}")
    return filepath

def generate_briefing():
    """ç”Ÿæˆæ¯æ—¥ç®€æŠ¥ä¸»æµç¨‹"""
    print("ğŸš€ CEX æ¯æ—¥ç®€æŠ¥ç”Ÿæˆå™¨ï¼ˆä¸­æ–‡ç‰ˆ - æ”¹è¿›URLè´¨é‡ï¼‰")
    print("=" * 50)
    
    # é‡‡é›†ä»Šæ—¥æƒ…æŠ¥
    data = collect_daily_intel()
    
    # ä¿å­˜
    save_intel(data)
    
    # è¾“å‡ºæ‘˜è¦
    print("\n" + "=" * 50)
    print("âœ… ç®€æŠ¥ç”Ÿæˆå®Œæˆ")
    print(f"ğŸ“… æ—¥æœŸ: {data['date']}")
    print(f"ğŸ“Š è­¦æŠ¥æ•°: {len(data.get('alerts', []))}")
    
    # ç»Ÿè®¡æœ‰URLçš„è­¦æŠ¥
    alerts_with_url = [a for a in data.get('alerts', []) if a.get('url')]
    print(f"ğŸ”— æœ‰æ¥æºé“¾æ¥: {len(alerts_with_url)}")
    
    return data

if __name__ == "__main__":
    data = generate_briefing()
